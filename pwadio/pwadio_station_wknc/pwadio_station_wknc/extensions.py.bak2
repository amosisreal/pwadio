from scrapy import signals, stats
from scrapy.exceptions import NotConfigured
from pwadio_be.models import ProcessingTime

class LogSpiderStats(object):

    def __init__(self, item_count):
        self.item_count = item_count
        self.items_scraped = 0
        #self.start_time = signals.engine_started
        #self.finish_time
        #self.finish_reason

    @classmethod
    def from_crawler(cls, crawler):
        if not crawler.settings.getbool('MYEXT_ENABLED'):
            raise NotConfigured

        item_count = crawler.settings.getint('MYEXT_ITEMCOUNT', 1000)

        ext = cls(item_count)

        crawler.signals.connect(ext.spider_opened, signal=signals.spider_opened)
        crawler.signals.connect(ext.spider_closed, signal=signals.spider_closed)
        crawler.signals.connect(ext.item_scraped, signal=signals.item_scraped)
        #crawler.signals.connect(ext.start_time, signal=signals.engine_started)

        #print "##~##~##~##~##~##~##~##~##"
        #print unicode(cls)
        #print(crawler.stats.get_stats())
        #print "##~##~##~##~##~##~##~##~##"
        return ext

    def spider_opened(self, spider):
        spider.log("##~##~##~##~##~##~##~ opened spider %s" % spider.name)


    def spider_closed(self, spider):
        spider.log("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~`")
        spider.log("##~##~##~##~##~##~##~ closed spider %s" % spider.name)
        #spider.log("Spider Start Time: " + self.get_stats())
        spider.log("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~`")


    def item_scraped(self, item, spider):
        self.items_scraped += 1
        spider.log("##~##~##~##~##~##~##~ added 1 item, total items: %d" % self.items_scraped)
        if self.items_scraped == self.item_count:
            spider.log("##~##~##~##~##~##~scraped %d items, resetting counter" % self.items_scraped)
            self.item_count = 0
